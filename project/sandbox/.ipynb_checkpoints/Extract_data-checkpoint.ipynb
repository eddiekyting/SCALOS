{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c8c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pip\n",
    "# pip.main([\"install\", \"openpyxl\"])\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297fa83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log2298 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2298.xlsx')\n",
    "df_log2320 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2320.xlsx')\n",
    "df_log2326 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2326.xlsx')\n",
    "df_log2331 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2331.xlsx')\n",
    "df_data2298 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2298.csv')\n",
    "df_data2320 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2320.csv')\n",
    "df_data2326 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2326.csv')\n",
    "df_data2331 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2331.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942f7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep:\n",
    "\n",
    "    def runlog_cleanup(df_log2298, df_log2320, df_log2326, df_log2331):\n",
    "        \n",
    "        # clean up uw2298\n",
    "        del df_log2298[\"Riley's Stress Level\"]                                    # delete unncessary column \n",
    "        df_log2298.rename(columns = {'FLAP L/R':'IB FLAP L/R'}, inplace = True)   # Rename inconsistant column\n",
    "        df_log2298.rename(columns = {'AIL L/R':'OB AIL L/R'}, inplace = True)     # Rename inconsistant column\n",
    "        df_log2298.rename(columns = {'LE DEF':'LE IB/OB'}, inplace = True)        # Rename inconsistant column\n",
    "        df_log2298.rename(columns = {'TRIP DEF':'TRIP DOTS'}, inplace = True)     # Rename inconsistant column\n",
    "        df_log2298.insert(1,'TEST', 2298)                                         # add entry number \n",
    "        df_log2298['Nacelle Blockage L/R']= np.nan\n",
    "        df_log2298['Spoiler L/R']= np.nan\n",
    "        temp = df_log2298['DATE']\n",
    "        del df_log2298['DATE']\n",
    "        df_log2298['DATE']= temp\n",
    "        df_log2298.columns.tolist() \n",
    "        # clean up uw2320\n",
    "        df_log2320.rename(columns = {'FLAP L/R':'IB FLAP L/R'}, inplace = True)\n",
    "        df_log2320.rename(columns = {'AIL L/R':'OB AIL L/R'}, inplace = True)\n",
    "        df_log2320.rename(columns = {'TRIP DEF':'TRIP DOTS'}, inplace = True)\n",
    "        df_log2320.insert(1,'TEST', 2320)\n",
    "        df_log2320['Nacelle Blockage L/R']= np.nan\n",
    "        df_log2320['Spoiler L/R']= np.nan\n",
    "        temp = df_log2320['DATE']\n",
    "        del df_log2320['DATE']\n",
    "        df_log2320['DATE']= temp\n",
    "        # clean up uw2326\n",
    "        df_log2326.insert(1,'TEST', 2326)\n",
    "        df_log2326['Nacelle Blockage L/R']= np.nan\n",
    "        df_log2326['Spoiler L/R']= np.nan\n",
    "        temp = df_log2326['DATE']\n",
    "        del df_log2326['DATE']\n",
    "        df_log2326['DATE']= temp\n",
    "        # clean up uw2331 \n",
    "        df_log2331.insert(1,'TEST', 2331)\n",
    "        # column title are consistant \n",
    "        if df_log2298.columns.tolist() !=  df_log2320.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2320 data is not right!\") \n",
    "\n",
    "        if df_log2298.columns.tolist() !=  df_log2326.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2326 data is not right!\")\n",
    "\n",
    "        if df_log2298.columns.tolist() !=  df_log2331.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2331 data is not right!\")\n",
    "\n",
    "        # Concatinate all run logs into single data frame\n",
    "        df_log = pd.concat([df_log2298, df_log2320, df_log2326, df_log2331], ignore_index=True,axis=0)\n",
    "\n",
    "        return df_log, df_log2298, df_log2320, df_log2326, df_log2331\n",
    "    \n",
    "    def data_cleanup(df_data2298, df_data2320, df_data2326, df_data2331):\n",
    "        if df_data2298.columns.tolist() !=  df_data2320.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2320 data is not right!\")\n",
    "\n",
    "        if df_data2298.columns.tolist() !=  df_data2326.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2326 data is not right!\")\n",
    "\n",
    "        if df_data2298.columns.tolist() !=  df_data2331.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2331 data is not right!\")\n",
    "\n",
    "        df_data = pd.concat([df_data2298, df_data2320, df_data2326, df_data2331], ignore_index=True,axis=0)\n",
    "        return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b34031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce10233",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1322901310.py, line 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for j in range(len(runnum))\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DataProcess:\n",
    "    \n",
    "#     def data_extract(df_log, df_data, test, runnum):\n",
    "#         # Unit test \n",
    "#         if type(test) != type(runnum): \n",
    "#             raise ValueError(\"Test entries and run numbers must be consistant\")    \n",
    "\n",
    "#         df_data_sub = pd.DataFrame()\n",
    "#         df_log_sub = pd.DataFrame()\n",
    "#         # Unit test \n",
    "#         for i in range(len(test)):\n",
    "#             # Entries must be integer\n",
    "#             if not isinstance(test[i], int) or not isinstance(runnum[i], int):\n",
    "#                 raise ValueError(\"Test entries and run numbers must be integer!\")\n",
    "\n",
    "#             # Entries must be not empty \n",
    "#             if not np.any(test[i]) or not np.any(runnum[i]):\n",
    "#                 raise ValueError(\"Test entries and run numbers must be not empty!\")\n",
    "\n",
    "#             # Test entries must be valid \n",
    "#             if not any(np.unique(df_log[df_log.columns.tolist()[1]]) == test[i]):\n",
    "#                 raise ValueError(\"Test entries are invalid!\")\n",
    "\n",
    "#             # Run number must be valid \n",
    "#             if runnum[i] < 0 or runnum[i] > np.max(df_log[df_log.columns.tolist()[0]][df_log[df_log.columns.tolist()[1]] == test[i]]):\n",
    "#                 raise ValueError(\"Run numbers are invalid!\")\n",
    "\n",
    "#             # Entries must be not weight tare \n",
    "#             if np.any(pd.isna(df_log[df_log.columns.tolist()[2]][(df_log[df_log.columns.tolist()[1]] == test[i]) & (df_log[df_log.columns.tolist()[1]] == runnum[i])])):\n",
    "#                 raise ValueError(\"Test num and corresponding run num is weight tare\")\n",
    "\n",
    "#             df_log_sub  = pd.concat([df_log_sub,  df_log[(df_log[df_log.columns.tolist()[1]] == test[i]) & (df_log[df_log.columns.tolist()[0]] == runnum[i])]], ignore_index = True, axis = 0)\n",
    "#             df_data_sub = pd.concat([df_data_sub, df_data[(df_data[df_data.columns.tolist()[1]] == test[i]) & (df_data[df_data.columns.tolist()[0]] == runnum[i])]], ignore_index = True, axis = 0) \n",
    "\n",
    "#         # Run type must be consistant\n",
    "#         if len(pd.unique(df_log_sub[df_log.columns.tolist()[4]][0])) > 1:\n",
    "#             raise ValueError(\"Run type is inconsistant!\")\n",
    "\n",
    "#         return df_log_sub, df_data_sub \n",
    "\n",
    "    def data_extract(df_log, df_data, test, runnum):\n",
    "        # Unit test\n",
    "        if type(test) != type(runnum):\n",
    "            raise ValueError(\"Test entries and run numbers must be consistent!\")\n",
    "\n",
    "        df_data_sub = pd.DataFrame()\n",
    "        df_log_sub = pd.DataFrame()\n",
    "        # Unit test\n",
    "        for i in range(len(test)):\n",
    "            # Test Entries must be integer\n",
    "            if not isinstance(test[i], int):\n",
    "                raise ValueError(\"Test entries must be integer!\")\n",
    "\n",
    "            # Entries must be not empty\n",
    "            if not np.any(test[i]) or not np.any(runnum[i]):\n",
    "                raise ValueError(\"Test entries and run numbers must be not empty!\")\n",
    "\n",
    "            # Test entries must be valid\n",
    "            if not any(np.unique(df_log[df_log.columns.tolist()[1]]) == test[i]):\n",
    "                raise ValueError(\"Test entries are invalid!\")\n",
    "\n",
    "            # Run number must be a list\n",
    "            if not isinstance(runnum[i], list):\n",
    "                raise ValueError(\"Run numbers are invalid!\")\n",
    "\n",
    "    #         len_i = len()\n",
    "            for j in range(len(runnum[i])):\n",
    "                # Each run number must be valid\n",
    "                if runnum[i][j] < 0 or runnum[i][j] > np.max(\n",
    "                        df_log[df_log.columns.tolist()[0]][df_log[df_log.columns.tolist()[1]] == test[i]]):\n",
    "                    raise ValueError(\"Run numbers are invalid!\")\n",
    "\n",
    "            # Entries must be not weight tare\n",
    "    #         for j in range(len_i):\n",
    "                if np.any(pd.isna(df_log[df_log.columns.tolist()[2]][(df_log[df_log.columns.tolist()[1]] == test[i]) & (\n",
    "                        df_log[df_log.columns.tolist()[1]] == runnum[i][j])])):\n",
    "                    raise ValueError(\"Test num and corresponding run num is weight tare\")\n",
    "\n",
    "    #         for j in range(len_i):\n",
    "                df_log_sub = pd.concat([df_log_sub, df_log[\n",
    "                    (df_log[df_log.columns.tolist()[1]] == test[i]) & (df_log[df_log.columns.tolist()[0]] == runnum[i][j])]],\n",
    "                                       ignore_index=True, axis=0)\n",
    "                df_data_sub = pd.concat([df_data_sub, df_data[\n",
    "                    (df_data[df_data.columns.tolist()[1]] == test[i]) & (df_data[df_data.columns.tolist()[0]] == runnum[i][j])]],\n",
    "                                        ignore_index=True, axis=0)\n",
    "\n",
    "            # Run type must be consistant\n",
    "        if len(pd.unique(df_log_sub[df_log.columns.tolist()[4]])) > 1:\n",
    "            raise ValueError(\"Run type is inconsistant!\")\n",
    "        df_log_sub[\"RUN NO.\"] = df_log_sub[\"RUN NO.\"].astype(int)\n",
    "\n",
    "        df_data_sub[[\"RUN\",\"TEST\"]] = df_data_sub[[\"RUN\",\"TEST\"]].astype(int)\n",
    "        \n",
    "        return df_log_sub, df_data_sub\n",
    "\n",
    "    def data_interp_derivative(df_log_sub, df_data_sub, test, runnum):\n",
    "        \n",
    "        if pd.unique(df_log_sub[df_log.columns.tolist()[4]]) == 'P6':\n",
    "            alphabeta = df_data_sub.columns.tolist()[3]\n",
    "        elif pd.unique(df_log_sub[df_log.columns.tolist()[4]]) == 'Y6':\n",
    "            alphabeta = df_data_sub.columns.tolist()[4]\n",
    "        else:\n",
    "            raise ValueError(\"Run type error!\")\n",
    "\n",
    "        max_list =[]\n",
    "        min_list =[]\n",
    "        for i in range(len(test)):\n",
    "            for j in range(len(runnum)):\n",
    "                max_list.append(np.max(df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i][j])]))\n",
    "                min_list.append(np.min(df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i][j])]))\n",
    "\n",
    "        alphabeta_interp= np.arange(np.ceil(np.max(min_list)), np.floor(np.min(max_list))+1, 1)\n",
    "\n",
    "        if np.min(alphabeta_interp) != np.ceil(np.max(min_list)) or np.max(alphabeta_interp) != np.floor(np.min(max_list)):\n",
    "            raise ValueError(\"Data range incorrect\")\n",
    "\n",
    "        df_data_sub_interp = pd.DataFrame()\n",
    "        df_data_sub_derivative = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(test)):\n",
    "            temp_interp = pd.DataFrame()\n",
    "            temp_derivative = pd.DataFrame()\n",
    "            for j in range(len(df_data_sub.columns.tolist())):\n",
    "                if j <= 8:\n",
    "                    if df_data_sub.columns.tolist()[j] == alphabeta: \n",
    "                        temp_interp[df_data_sub.columns.tolist()[j]] = alphabeta_interp\n",
    "                        temp_derivative[df_data_sub.columns.tolist()[j]] = alphabeta_interp\n",
    "                    else:\n",
    "                        temp_fun = sp.interpolate.interp1d(\n",
    "                                    df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i])],\n",
    "                                    df_data_sub[df_data_sub.columns.tolist()[j]][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i])],\n",
    "                                    kind = 'nearest')\n",
    "                        temp_interp[df_data_sub.columns.tolist()[j]] = temp_fun(alphabeta_interp)\n",
    "                        temp_derivative[df_data_sub.columns.tolist()[j]] = temp_fun(alphabeta_interp)\n",
    "                else:\n",
    "                    temp_fun = sp.interpolate.interp1d(\n",
    "                                df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i])],\n",
    "                                df_data_sub[df_data_sub.columns.tolist()[j]][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i])],\n",
    "                                kind = 'linear')\n",
    "                    temp_interp[df_data_sub.columns.tolist()[j]] = temp_fun(alphabeta_interp)\n",
    "                    temp_derivative[df_data_sub.columns.tolist()[j]] = np.gradient(temp_fun(alphabeta_interp), alphabeta_interp)\n",
    "\n",
    "\n",
    "            df_data_sub_interp = pd.concat([df_data_sub_interp, temp_interp], ignore_index = True, axis = 0) \n",
    "            df_data_sub_derivative = pd.concat([df_data_sub_derivative, temp_derivative], ignore_index = True, axis = 0) \n",
    "\n",
    "        return df_data_sub_interp, df_data_sub_derivative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8e103",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DataPlot:\n",
    "    \n",
    "    def plt_data(plotvars, df_log_sub, df_data_sub, test, runnum):\n",
    "        if pd.unique(df_log_sub[df_log.columns.tolist()[4]]) == 'P6':\n",
    "            alphabeta = df_data_sub.columns.tolist()[3]\n",
    "            x_label = \"\\\\alpha\"\n",
    "        elif pd.unique(df_log_sub[df_log.columns.tolist()[4]]) == 'Y6':\n",
    "            alphabeta = df_data_sub.columns.tolist()[4]\n",
    "            x_label = \"\\\\beta\"\n",
    "        else:\n",
    "            raise ValueError(\"Run type error!\")\n",
    "\n",
    "        for j in range(len(plotvars)):\n",
    "            plt.figure()\n",
    "            for i in range(len(test)):\n",
    "                for k in range(len(runnum[i])):\n",
    "                    plt.scatter(df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i][k])],\n",
    "                         df_data_sub[plotvars[j]][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i][k])], \n",
    "                         label='UW'+str(test[i])+' Run'+str(runnum[i][k]))\n",
    "            plt.xlabel(r\"$\"+x_label+\" (^\\circ)$\")\n",
    "            if plotvars[j] == \"LOD\":\n",
    "                y_label = \"C_L/C_D\"\n",
    "            else:\n",
    "                y_label = plotvars[j][0]+\"_\"+plotvars[j][1]+\"(\"+plotvars[j][2:]+\") \"\n",
    "            plt.ylabel(r\"$\"+y_label+ \"$\")\n",
    "            if j == 0:\n",
    "                plt.legend()\n",
    "            plt.title(r\"$\"+y_label + \" vs. \"+ x_label+\"$\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70468b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log, df_log2298, df_log2320, df_log2326, df_log2331 = DataPrep.runlog_cleanup(df_log2298, df_log2320, df_log2326, df_log2331 )\n",
    "df_data = DataPrep.data_cleanup(df_data2298, df_data2320, df_data2326, df_data2331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_log[np.isnan(df_log[\"WT.\\nTARE\\nRUN\"]) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af906a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = [2320, 2320, 2320, 2320, 2320]\n",
    "# runnum = [49, 51, 37, 56, 57]\n",
    "# df_log_sub, df_data_sub = DataProcess.data_extract(df_log, df_data, test, runnum)\n",
    "runnum[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca530a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a386f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test = [2320, 2320, 2298, 2298, 2298]\n",
    "# runnum = [[49, 50, 51, 52], \n",
    "#           [116, 119, 120, 121, 122], \n",
    "#           [37,], \n",
    "#           [87, 88], \n",
    "#           [47, 48, 49, 50, 51]]\n",
    "test = [2298]\n",
    "runnum = [[47, 48, 49, 50, 51]]\n",
    "\n",
    "df_log_sub, df_data_sub = DataProcess.data_extract(df_log, df_data, test, runnum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126fe11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotvars = [\"CLSA\", \"CDSA\", \"CYSA\", \"CMSA25\", \"CNSA25\", \"CRSA25\", \"LOD\"]\n",
    "DataPlot.plt_data(plotvars, df_log_sub, df_data_sub, test, runnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bf97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if pd.unique(df_log_sub[df_log.columns.tolist()[4]]) == 'P6':\n",
    "    alphabeta = df_data_sub.columns.tolist()[3]\n",
    "elif pd.unique(df_log_sub[df_log.columns.tolist()[4]]) == 'Y6':\n",
    "    alphabeta = df_data_sub.columns.tolist()[4]\n",
    "else:\n",
    "    raise ValueError(\"Run type error!\")\n",
    "    \n",
    "max_list =[]\n",
    "min_list =[]\n",
    "\n",
    "for i in range(len(test)):\n",
    "    for j in range(len(runnum[i])):\n",
    "        max_list.append(np.max(df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i][j])]))\n",
    "        min_list.append(np.min(df_data_sub[alphabeta][(df_data_sub[df_data_sub.columns.tolist()[1]] == test[i]) & (df_data_sub[df_data_sub.columns.tolist()[0]] == runnum[i][j])]))\n",
    "\n",
    "alphabeta_interp= np.arange(np.ceil(np.max(min_list)), np.floor(np.min(max_list))+1, 1)\n",
    "\n",
    "if np.min(alphabeta_interp) != np.ceil(np.max(min_list)) or np.max(alphabeta_interp) != np.floor(np.min(max_list)):\n",
    "    raise ValueError(\"Data range incorrect\")\n",
    "\n",
    "df_data_sub_interp = pd.DataFrame()\n",
    "df_data_sub_derivative = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8fe9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be103eab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_data_sub_interp, df_data_sub_derivative = DataProcess.data_interp_derivative(df_log_sub, df_data_sub, test, runnum)\n",
    "DataPlot.plt_data(plotvars, df_log_sub, df_data_sub_derivative, test, runnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c5c38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085e702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
