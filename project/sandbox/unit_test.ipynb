{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e028ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pip\n",
    "# pip.main([\"install\", \"openpyxl\"])\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201454dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DataPrep: Data pre-process and preperation for manipulation and process\n",
    "\n",
    "parameters:\n",
    "    arg df_logXXXX:  data log with entry numbers (.xlsx file)\n",
    "\n",
    "    arg df_dataXXXX: data set with entry numbers (.xlsx file)\n",
    "\n",
    "return:\n",
    "    df_logXXXX:  Cleaned up test data sets( data frame)\n",
    "\n",
    "    df_log:      Concatinated data logs (data frame)\n",
    "\n",
    "    df_data:     Concatinated data sets (data frame)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DataPrep:\n",
    "\n",
    "    \"\"\"\n",
    "    function: runlog_cleanup\n",
    "\n",
    "        clean up and align variables\n",
    "\n",
    "    function: data_cleanup\n",
    "\n",
    "        check data sets and concatinate them into single data set\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            initialization of variables\n",
    "\n",
    "        parameters:\n",
    "            arg df_log:  Data log from data_prep output (data frame)\n",
    "\n",
    "            arg df_data: Data set from data_prep output (data frame)\n",
    "\n",
    "            arg test:    Test entries (list)\n",
    "\n",
    "            arg run_num: Run numbers correspondign to test entires (list)\n",
    "\n",
    "        return:\n",
    "            data logs and sets\n",
    "        \"\"\"\n",
    "        # import data log\n",
    "        self.df_log2298 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2298.xlsx')\n",
    "        self.df_log2320 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2320.xlsx')\n",
    "        self.df_log2326 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2326.xlsx')\n",
    "        self.df_log2331 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2331.xlsx')\n",
    "        # import data sets\n",
    "        self.df_data2298 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2298.csv')\n",
    "        self.df_data2320 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2320.csv')\n",
    "        self.df_data2326 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2326.csv')\n",
    "        self.df_data2331 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2331.csv')\n",
    "\n",
    "\n",
    "    def runlog_cleanup(self):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            runlog_cleanup\n",
    "\n",
    "        parameters:\n",
    "            arg df_logXXXX = data log with entry numbers (.xlsx file)\n",
    "\n",
    "        return:\n",
    "            df_log:     Concatinate data log from inputs\n",
    "\n",
    "            df_logXXXX: Clean up individual data logs\n",
    "        \"\"\"\n",
    "        df_log2298 = self.df_log2298\n",
    "        df_log2320 = self.df_log2320\n",
    "        df_log2326 = self.df_log2326\n",
    "        df_log2331 = self.df_log2331\n",
    "    # clean up uw2298\n",
    "        # delete unncessary column\n",
    "        del df_log2298[\"Riley's Stress Level\"]\n",
    "        # rename entries titles\n",
    "        df_log2298.rename(columns = {'FLAP L/R':'IB FLAP L/R'}, inplace = True)\n",
    "        df_log2298.rename(columns = {'AIL L/R':'OB AIL L/R'}, inplace = True)\n",
    "        df_log2298.rename(columns = {'LE DEF':'LE IB/OB'}, inplace = True)\n",
    "        df_log2298.rename(columns = {'TRIP DEF':'TRIP DOTS'}, inplace = True)\n",
    "        # add enties\n",
    "        df_log2298.insert(1,'TEST', 2298)\n",
    "        df_log2298['Nacelle Blockage L/R']= np.nan\n",
    "        df_log2298['Spoiler L/R']= np.nan\n",
    "        temp = df_log2298['DATE']\n",
    "        del df_log2298['DATE']\n",
    "        df_log2298['DATE']= temp\n",
    "        df_log2298.columns.tolist()\n",
    "\n",
    "    # clean up uw2320\n",
    "        # rename entries titles\n",
    "        df_log2320.rename(columns = {'FLAP L/R':'IB FLAP L/R'}, inplace = True)\n",
    "        df_log2320.rename(columns = {'AIL L/R':'OB AIL L/R'}, inplace = True)\n",
    "        df_log2320.rename(columns = {'TRIP DEF':'TRIP DOTS'}, inplace = True)\n",
    "        # add enties\n",
    "        df_log2320.insert(1,'TEST', 2320)\n",
    "        df_log2320['Nacelle Blockage L/R']= np.nan\n",
    "        df_log2320['Spoiler L/R']= np.nan\n",
    "        temp = df_log2320['DATE']\n",
    "        del df_log2320['DATE']\n",
    "        df_log2320['DATE']= temp\n",
    "\n",
    "    # clean up uw2326\n",
    "        # add enties\n",
    "        df_log2326.insert(1,'TEST', 2326)\n",
    "        df_log2326['Nacelle Blockage L/R']= np.nan\n",
    "        df_log2326['Spoiler L/R']= np.nan\n",
    "        temp = df_log2326['DATE']\n",
    "        del df_log2326['DATE']\n",
    "        df_log2326['DATE']= temp\n",
    "\n",
    "    # clean up uw2331\n",
    "        df_log2331.insert(1,'TEST', 2331)\n",
    "\n",
    "        # column title are consistant\n",
    "        if df_log2298.columns.tolist() !=  df_log2320.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2320 data is not right!\")\n",
    "\n",
    "        if df_log2298.columns.tolist() !=  df_log2326.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2326 data is not right!\")\n",
    "\n",
    "        if df_log2298.columns.tolist() !=  df_log2331.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2331 data is not right!\")\n",
    "\n",
    "        # Concatinate all run logs into single data frame\n",
    "        df_log = pd.concat([df_log2298,\n",
    "                            df_log2320,\n",
    "                            df_log2326,\n",
    "                            df_log2331],\n",
    "                           ignore_index=True,axis=0)\n",
    "\n",
    "        return df_log, df_log2298, df_log2320, df_log2326, df_log2331\n",
    "\n",
    "    def data_cleanup(self):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            data_cleanup\n",
    "\n",
    "        parameters:\n",
    "            arg df_dataXXXX = data set with entry numbers (.xlsx file)\n",
    "\n",
    "        return:\n",
    "            df_set:     Concatinate data sets from inputs\n",
    "        \"\"\"\n",
    "        df_data2298 = self.df_data2298\n",
    "        df_data2320 = self.df_data2320\n",
    "        df_data2326 = self.df_data2326\n",
    "        df_data2331 = self.df_data2331\n",
    "\n",
    "        if df_data2298.columns.tolist() !=  df_data2320.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2320 data is not right!\")\n",
    "\n",
    "        if df_data2298.columns.tolist() !=  df_data2326.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2326 data is not right!\")\n",
    "\n",
    "        if df_data2298.columns.tolist() !=  df_data2331.columns.tolist():\n",
    "            raise ValueError(\"Either 2298 or 2331 data is not right!\")\n",
    "\n",
    "        #  Concatinate all data into single data frame\n",
    "        df_data = pd.concat([df_data2298,\n",
    "                             df_data2320,\n",
    "                             df_data2326,\n",
    "                             df_data2331],\n",
    "                            ignore_index=True,axis=0)\n",
    "\n",
    "        return df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb09ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess:\n",
    "\n",
    "    \"\"\"\n",
    "    function: data_extract\n",
    "\n",
    "        Extract data from input test entries with corresponding run numbers\n",
    "\n",
    "    function: data_interp_derivatives\n",
    "\n",
    "        Truncate data within max min and min max range (no exterpolation)\n",
    "        Linear interpolate data on with integer pitch (P) or yaw (Y) run\n",
    "        Compute derivaties with respect to alpha or beta\n",
    "    \"\"\"\n",
    "    def __init__(self, df_log, df_data, test, run_num):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            initialization of variables\n",
    "\n",
    "        parameters:\n",
    "            arg df_log:  Data log from data_prep output (data frame)\n",
    "\n",
    "            arg df_data: Data set from data_prep output (data frame)\n",
    "\n",
    "            arg test:    Test entries (list)\n",
    "\n",
    "            arg run_num: Run numbers correspondign to test entires (list)\n",
    "\n",
    "        return:\n",
    "            self\n",
    "        \"\"\"\n",
    "\n",
    "        self.df_log = df_log\n",
    "        self.df_data = df_data\n",
    "        self.test = test\n",
    "        self.run_num = run_num\n",
    "\n",
    "    def data_extract(self):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            Data extraction\n",
    "\n",
    "        parameters:\n",
    "            arg df_log:  Data log from data_prep output (data frame)\n",
    "\n",
    "            arg df_data: Data set from data_prep output (data frame)\n",
    "\n",
    "            arg test:    Test entries (list)\n",
    "\n",
    "            arg run_num: Run numbers correspondign to test entires (list)\n",
    "\n",
    "        return:\n",
    "            df_log_sub:  Extracted data log from test and run numbers (data frame)\n",
    "\n",
    "            df_data_sub: Extracted data set from test and run numbers (data frame)\n",
    "        \"\"\"\n",
    "\n",
    "        df_log = self.df_log\n",
    "        df_data = self.df_data\n",
    "        test = self.test\n",
    "        run_num = self.run_num\n",
    "        # Unit test\n",
    "        if len(test) != len(run_num):\n",
    "            raise ValueError(\"Test entries and run numbers must be consistent!\")\n",
    "\n",
    "        df_data_sub = pd.DataFrame()\n",
    "        df_log_sub = pd.DataFrame()\n",
    "        # Unit test\n",
    "        for i in range(len(test)):\n",
    "            # Test Entries must be integer\n",
    "            if not isinstance(test[i], int):\n",
    "                raise ValueError(\"Test entries must be integer!\")\n",
    "\n",
    "            # Entries must be not empty\n",
    "            if not np.any(test[i]) or not np.any(run_num[i]):\n",
    "                raise ValueError(\"Test entries and run numbers must be not empty!\")\n",
    "\n",
    "            # Test entries must be valid\n",
    "            if not any(np.unique(df_log[df_log.columns.tolist()[1]]) == test[i]):\n",
    "                raise ValueError(\"Test entries are invalid!\")\n",
    "\n",
    "            # Run number must be a list\n",
    "            if not isinstance(run_num[i], list):\n",
    "                raise ValueError(\"Run numbers are invalid!\")\n",
    "\n",
    "            for j in range(len(run_num[i])):\n",
    "                # Each run number must be valid\n",
    "                if run_num[i][j] < 0 or run_num[i][j] > np.max(\n",
    "                    df_log[df_log.columns.tolist()[0]][\n",
    "                        df_log[df_log.columns.tolist()[1]] == test[i]]):\n",
    "                    raise ValueError(\"Run numbers are invalid!\")\n",
    "\n",
    "                # Entries must be not weight tare\n",
    "                if np.any( pd.isna( df_log[df_log.columns.tolist()[2]][\n",
    "                    (df_log[df_log.columns.tolist()[1]] == test[i]) &\n",
    "                    (df_log[df_log.columns.tolist()[0]] == run_num[i][j])\n",
    "                ])):\n",
    "                    raise ValueError(\"Test num and corresponding run num is weight tare\")\n",
    "\n",
    "                # Concatinate sub data log\n",
    "                df_log_sub = pd.concat(\n",
    "                    [df_log_sub,\n",
    "                     df_log[\n",
    "                        (df_log[df_log.columns.tolist()[1]] == test[i]) &\n",
    "                        (df_log[df_log.columns.tolist()[0]] == run_num[i][j]\n",
    "                        )]], ignore_index=True, axis=0)\n",
    "                # Concatinate sub data set\n",
    "                df_data_sub = pd.concat(\n",
    "                    [df_data_sub,\n",
    "                     df_data[(df_data[df_data.columns.tolist()[1]] == test[i]) &\n",
    "                             (df_data[df_data.columns.tolist()[0]] == run_num[i][j])]\n",
    "                    ],ignore_index=True, axis=0)\n",
    "\n",
    "        # Run type must be consistant\n",
    "        if len(pd.unique(df_log_sub[df_log.columns.tolist()[4]])) > 1:\n",
    "            raise ValueError(\"Run type is inconsistant!\")\n",
    "        df_log_sub[\"RUN NO.\"] = df_log_sub[\"RUN NO.\"].astype(int)\n",
    "\n",
    "        df_data_sub[[\"RUN\",\"TEST\"]] = df_data_sub[[\"RUN\",\"TEST\"]].astype(int)\n",
    "\n",
    "        return df_log_sub, df_data_sub\n",
    "\n",
    "    def data_interp_derivative(self):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            Data inpterolation and derivatives\n",
    "\n",
    "        parameters:\n",
    "            arg df_log:  Data log from data_extract output (data frame)\n",
    "\n",
    "            arg df_data: Data set from data_extract output (data frame)\n",
    "\n",
    "            arg test:    Test entries (list)\n",
    "\n",
    "            arg run_num: Run numbers correspondign to test entires (list)\n",
    "\n",
    "        return:\n",
    "            df_data_interp:      Interpoalted data sets extracted data sets (data frame)\n",
    "\n",
    "            df_data_derivative:  Data derivatives from extracted data sets (data frame)\n",
    "        \"\"\"\n",
    "\n",
    "        df_log = self.df_log\n",
    "        df_data = self.df_data\n",
    "        test = self.test\n",
    "        run_num = self.run_num\n",
    "\n",
    "        # Check run type\n",
    "        if pd.unique(df_log[df_log.columns.tolist()[4]]) == 'P6':\n",
    "            alphabeta = df_data.columns.tolist()[3]\n",
    "        elif pd.unique(df_log[df_log.columns.tolist()[4]]) == 'Y6':\n",
    "            alphabeta = df_data.columns.tolist()[4]\n",
    "        else:\n",
    "            raise ValueError(\"Run type error!\")\n",
    "\n",
    "        max_list =[]\n",
    "        min_list =[]\n",
    "\n",
    "        # find the max and min among all runs\n",
    "        for i in range(len(test)):\n",
    "            for j in range(len(run_num[i])):\n",
    "                max_list.append(np.max(\n",
    "                    df_data[alphabeta][\n",
    "                        (df_data[df_data.columns.tolist()[1]] == test[i]) &\n",
    "                        (df_data[df_data.columns.tolist()[0]] == run_num[i][j])\n",
    "                    ]))\n",
    "                min_list.append(\n",
    "                    np.min(df_data[alphabeta][\n",
    "                        (df_data[df_data.columns.tolist()[1]] == test[i]) &\n",
    "                        (df_data[df_data.columns.tolist()[0]] == run_num[i][j])\n",
    "                    ]))\n",
    "        # interpolate alpha or beta from min to max\n",
    "        alphabeta_interp= np.arange(np.ceil(np.max(min_list)), np.floor(np.min(max_list))+1, 1)\n",
    "\n",
    "        # Check interp data not extrapolate\n",
    "        if np.min(alphabeta_interp) != np.ceil(np.max(min_list)) or np.max(\n",
    "            alphabeta_interp) != np.floor(np.min(max_list)):\n",
    "            raise ValueError(\"Data range incorrect\")\n",
    "\n",
    "        df_data_interp = pd.DataFrame()\n",
    "        df_data_derivative = pd.DataFrame()\n",
    "\n",
    "        # Loop through tests and run numbers\n",
    "        for i in range(len(test)):\n",
    "            temp_interp = pd.DataFrame()\n",
    "            temp_derivative = pd.DataFrame()\n",
    "            for k in range(len(run_num[i])):\n",
    "                for j in range(len(df_data.columns.tolist())):\n",
    "                    # Variables do not need to be interpreted\n",
    "                    if j <= 8:\n",
    "                        if df_data.columns.tolist()[j] == alphabeta:\n",
    "                            temp_interp[df_data.columns.tolist()[j]] = alphabeta_interp\n",
    "                            temp_derivative[df_data.columns.tolist()[j]] = alphabeta_interp\n",
    "                        else:\n",
    "                            temp_fun = sp.interpolate.interp1d(\n",
    "                                df_data[alphabeta][(\n",
    "                                    df_data[df_data.columns.tolist()[1]] == test[i]\n",
    "                                ) & (\n",
    "                                    df_data[df_data.columns.tolist()[0]] == run_num[i][k]\n",
    "                                )],\n",
    "                                df_data[df_data.columns.tolist()[j]][\n",
    "                                    (df_data[df_data.columns.tolist()[1]] == test[i]) &\n",
    "                                    (df_data[df_data.columns.tolist()[0]] == run_num[i][k]\n",
    "                                    )], kind = 'nearest')\n",
    "                            temp_interp[df_data.columns.tolist()[j]] = temp_fun(\n",
    "                                alphabeta_interp)\n",
    "                            temp_derivative[df_data.columns.tolist()[j]] = temp_fun(\n",
    "                                alphabeta_interp)\n",
    "                    else:\n",
    "                        temp_fun = sp.interpolate.interp1d(\n",
    "                            df_data[alphabeta][(\n",
    "                                df_data[df_data.columns.tolist()[1]] == test[i]\n",
    "                            ) & (\n",
    "                                df_data[df_data.columns.tolist()[0]] == run_num[i][k]\n",
    "                            )], df_data[df_data.columns.tolist()[j]][(\n",
    "                                df_data[df_data.columns.tolist()[1]] == test[i]\n",
    "                            ) & (\n",
    "                                df_data[df_data.columns.tolist()[0]] == run_num[i][k]\n",
    "                            )], kind = 'linear')\n",
    "                        temp_interp[df_data.columns.tolist()[j]] = temp_fun(\n",
    "                            alphabeta_interp)\n",
    "                        temp_derivative[df_data.columns.tolist()[j]] = np.gradient(\n",
    "                            temp_fun(alphabeta_interp), alphabeta_interp)\n",
    "\n",
    "                # Concatinate data interpolation\n",
    "                df_data_interp = pd.concat(\n",
    "                    [df_data_interp, temp_interp]\n",
    "                    , ignore_index = True, axis = 0)\n",
    "\n",
    "                # Concatinate data derivatives\n",
    "                df_data_derivative = pd.concat(\n",
    "                    [df_data_derivative, temp_derivative]\n",
    "                    , ignore_index = True, axis = 0)\n",
    "\n",
    "        return df_data_interp, df_data_derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f4bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DataPlot: Data extract, interpolation and derivatives\n",
    "\n",
    "parameters:\n",
    "    arg plot_type: Plot type specificaiton (to be complete)\n",
    "\n",
    "    arg plot_vars: Plot variables from data set variables\n",
    "\n",
    "    arg df_log:    Data log from data_prep output (data frame)\n",
    "\n",
    "    arg df_data:   Data set from data_prep output (data frame)\n",
    "\n",
    "    arg test:      Test entries (list)\n",
    "\n",
    "    arg run_num:   Run numbers correspondign to test entires (list)\n",
    "\n",
    "return:\n",
    "    Plots\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DataPlot:\n",
    "\n",
    "    \"\"\"\n",
    "    function: plt_data\n",
    "\n",
    "        Plot input data for visulization\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, plot_vars, df_log, df_data, test, run_num):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            initialization of variables\n",
    "\n",
    "        parameters:\n",
    "            arg plot_type: Plot type specificaiton (to be complete)\n",
    "\n",
    "            arg plot_vars: Plot variables from data set variables\n",
    "\n",
    "            arg df_log:    Data log from data_prep output (data frame)\n",
    "\n",
    "            arg df_data:   Data set from data_prep output (data frame)\n",
    "\n",
    "            arg test:      Test entries (list)\n",
    "\n",
    "            arg run_num:   Run numbers correspondign to test entires (list)\n",
    "\n",
    "        return:\n",
    "            self\n",
    "        \"\"\"\n",
    "#         self.plot_type = plot_type\n",
    "        self.plot_vars = plot_vars\n",
    "        self.df_log = df_log\n",
    "        self.df_data = df_data\n",
    "        self.test = test\n",
    "        self.run_num = run_num\n",
    "\n",
    "    def plt_data(self):\n",
    "        \"\"\"\n",
    "        function:\n",
    "            Plot data\n",
    "\n",
    "        parameters:\n",
    "            arg plot_type: Plot type specificaiton (to be complete)\n",
    "\n",
    "            arg plot_vars: Plot variables from data set variables\n",
    "\n",
    "            arg df_log:    Data log from data_prep output (data frame)\n",
    "\n",
    "            arg df_data:   Data set from data_prep output (data frame)\n",
    "\n",
    "            arg test:      Test entries (list)\n",
    "\n",
    "            arg run_num:   Run numbers correspondign to test entires (list)\n",
    "\n",
    "        return:\n",
    "            plots\n",
    "        \"\"\"\n",
    "#         plot_type = self.plot_type\n",
    "        plot_vars = self.plot_vars\n",
    "        df_log = self.df_log\n",
    "        df_data = self.df_data\n",
    "        test = self.test\n",
    "        run_num = self.run_num\n",
    "\n",
    "        # Run type must be consistant\n",
    "        if pd.unique(df_log[df_log.columns.tolist()[4]]) == 'P6':\n",
    "            alphabeta = df_data.columns.tolist()[3]\n",
    "            x_label = \"\\\\alpha\"\n",
    "        elif pd.unique(df_log[df_log.columns.tolist()[4]]) == 'Y6':\n",
    "            alphabeta = df_data.columns.tolist()[4]\n",
    "            x_label = \"\\\\beta\"\n",
    "        else:\n",
    "            raise ValueError(\"Run type error!\")\n",
    "\n",
    "        # Plot data\n",
    "        for j in range(len(plot_vars)):\n",
    "            plt.figure()\n",
    "            for i in range(len(test)):\n",
    "                for k in range(len(run_num[i])):\n",
    "                    plt.scatter(\n",
    "                        df_data[alphabeta][\n",
    "                            (df_data[df_data.columns.tolist()[1]] == test[i]) &\n",
    "                            (df_data[df_data.columns.tolist()[0]] == run_num[i][k])],\n",
    "                        df_data[plot_vars[j]][\n",
    "                            (df_data[df_data.columns.tolist()[1]] == test[i]) &\n",
    "                            (df_data[df_data.columns.tolist()[0]] == run_num[i][k])],\n",
    "                        label='UW'+str(test[i])+' Run'+str(run_num[i][k]))\n",
    "            plt.xlabel(r\"$\"+x_label+r\" (^\\circ)$\")\n",
    "            if plot_vars[j] == \"LOD\":\n",
    "                y_label = \"C_L/C_D\"\n",
    "            else:\n",
    "                y_label = plot_vars[j][0]+\"_\"+plot_vars[j][1]+\"(\"+plot_vars[j][2:]+\") \"\n",
    "            plt.ylabel(r\"$\"+y_label+ \"$\")\n",
    "            # Obly display legend on first plot\n",
    "            if j == 0:\n",
    "                plt.legend()\n",
    "            plt.title(r\"$\"+y_label + \" vs. \"+ x_label+\"$\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e62324",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataprep.data_runlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54879dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.347s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DataPrep test script\n",
    "\"\"\"\n",
    "import unittest\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from src import DataPrep\n",
    "\n",
    "# Define a class in which the tests will run\n",
    "class TestDataPrep(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    Unit test class\n",
    "\n",
    "        smoke test    = function working properly \n",
    "        one shot test = function work as expected \n",
    "        edge tes      = incorrect input detection\n",
    "    \"\"\"\n",
    "    def test_runlog_cleanup_smoke(self):\n",
    "        \"\"\"\n",
    "        smoke test\n",
    "\n",
    "        check if the test run through \n",
    "        \"\"\"\n",
    "        self.df_log2298 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2298.xlsx')\n",
    "        self.df_log2320 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2320.xlsx')\n",
    "        self.df_log2326 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2326.xlsx')\n",
    "        self.df_log2331 = pd.read_excel(r'~/SCALOS/project/runlogs/Autosort Run Log 2331.xlsx')\n",
    "        DataPrep.runlog_cleanup(self)\n",
    "\n",
    "    def test_data_cleanup_smoke(self):\n",
    "        \"\"\"\n",
    "        smoke test\n",
    "\n",
    "        check if the test run through \n",
    "        \"\"\"\n",
    "        self.df_data2298 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2298.csv')\n",
    "        self.df_data2320 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2320.csv')\n",
    "        self.df_data2326 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2326.csv')\n",
    "        self.df_data2331 = pd.read_csv(r'~/SCALOS/project/data/finaldata_uw2331.csv')\n",
    "        DataPrep.data_cleanup(self)\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestDataPrep)\n",
    "_ = unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feaf700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
